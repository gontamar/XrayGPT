                ğŸ”— Complete Line-by-Line Code Connection Trace for XrayGPT Training                          â”‚
â”‚                                                                                                                      â”‚
â”‚                                       ğŸ“ PHASE 1: Entry Point & Initialization                                       â”‚
â”‚                                                                                                                      â”‚
â”‚                                                                                                                      â”‚
â”‚  ğŸ“ train.py                                                                                                         â”‚
â”‚  â”œâ”€â”€ Line 73: def main():                                                                                            â”‚
â”‚  â”œâ”€â”€ Line 78:     job_id = now()                                                                                     â”‚
â”‚  â”‚   â””â”€â”€ ğŸ”— CALLS: xraygpt/common/utils.py::now()                                                                    â”‚
â”‚  â”‚                                                                                                                   â”‚
â”‚  â”œâ”€â”€ Line 80:     cfg = Config(parse_args())                                                                         â”‚
â”‚  â”‚   â”œâ”€â”€ ğŸ”— CALLS: train.py::parse_args() [Line 34-50]                                                               â”‚
â”‚  â”‚   â””â”€â”€ ğŸ”— CALLS: xraygpt/common/config.py::Config.__init__()                                                       â”‚
â”‚  â”‚                                                                                                                   â”‚
â”‚  â”œâ”€â”€ Line 82:     init_distributed_mode(cfg.run_cfg)                                                                 â”‚
â”‚  â”‚   â””â”€â”€ ğŸ”— CALLS: xraygpt/common/dist_utils.py::init_distributed_mode()                                             â”‚
â”‚  â”‚                                                                                                                   â”‚
â”‚  â”œâ”€â”€ Line 84:     setup_seeds(cfg)                                                                                   â”‚
â”‚  â”‚   â””â”€â”€ ğŸ”— CALLS: train.py::setup_seeds() [Line 53-61]                                                              â”‚
â”‚  â”‚                                                                                                                   â”‚
â”‚  â”œâ”€â”€ Line 87:     setup_logger()                                                                                     â”‚
â”‚  â”‚   â””â”€â”€ ğŸ”— CALLS: xraygpt/common/logger.py::setup_logger()                                                          â”‚
â”‚  â”‚                                                                                                                   â”‚
â”‚  â”œâ”€â”€ Line 89:     cfg.pretty_print()                                                                                 â”‚
â”‚  â”‚   â””â”€â”€ ğŸ”— CALLS: xraygpt/common/config.py::Config.pretty_print()                                                   â”‚
â”‚  â”‚                                                                                                                   â”‚
â”‚  â”œâ”€â”€ Line 91:     task = tasks.setup_task(cfg)                                                                       â”‚
â”‚  â”‚   â””â”€â”€ ğŸ”— CALLS: xraygpt/tasks/__init__.py::setup_task() [Line 12]                                                 â”‚
â”‚  â”‚       â”œâ”€â”€ Line 15: task_name = cfg.run_cfg.task                                                                   â”‚
â”‚  â”‚       â””â”€â”€ Line 16: task = registry.get_task_class(task_name).setup_task(cfg=cfg)                                  â”‚
â”‚  â”‚           â”œâ”€â”€ ğŸ”— CALLS: xraygpt/common/registry.py::get_task_class() [Line 239]                                   â”‚
â”‚  â”‚           â”‚   â””â”€â”€ ğŸ”— RETURNS: ImageTextPretrainTask (from xraygpt/tasks/image_text_pretrain.py)                   â”‚
â”‚  â”‚           â””â”€â”€ ğŸ”— CALLS: xraygpt/tasks/base_task.py::BaseTask.setup_task() [Line 27]                               â”‚
â”‚  â”‚               â””â”€â”€ ğŸ”— RETURNS: ImageTextPretrainTask instance                                                      â”‚
â”‚  â”‚                                                                                                                   â”‚
â”‚  â”œâ”€â”€ Line 92:     datasets = task.build_datasets(cfg)                                                                â”‚
â”‚  â”‚   â””â”€â”€ ğŸ”— CALLS: xraygpt/tasks/base_task.py::build_datasets() [Line 36]                                            â”‚
â”‚  â”‚       â”œâ”€â”€ Line 50: datasets_config = cfg.datasets_cfg                                                             â”‚
â”‚  â”‚       â”œâ”€â”€ Line 54: for name in datasets_config:                                                                   â”‚
â”‚  â”‚       â”œâ”€â”€ Line 55:     dataset_config = datasets_config[name]                                                     â”‚
â”‚  â”‚       â”œâ”€â”€ Line 57:     builder = registry.get_builder_class(name)(dataset_config)                                 â”‚
â”‚  â”‚       â”‚   â”œâ”€â”€ ğŸ”— CALLS: xraygpt/common/registry.py::get_builder_class() [Line 231]                                â”‚
â”‚  â”‚       â”‚   â”‚   â””â”€â”€ ğŸ”— RETURNS: MIMICBuilder or OpenIBuilder                                                        â”‚
â”‚  â”‚       â”‚   â””â”€â”€ ğŸ”— CALLS: xraygpt/datasets/builders/image_text_pair_builder.py::MIMICBuilder.__init__()             â”‚
â”‚  â”‚       â”œâ”€â”€ Line 58:     dataset = builder.build_datasets()                                                         â”‚
â”‚  â”‚       â”‚   â””â”€â”€ ğŸ”— CALLS: xraygpt/datasets/builders/image_text_pair_builder.py::MIMICBuilder.build_datasets() [Lin  â”‚
â”‚  22]                                                                                                                 â”‚
â”‚  â”‚       â”‚       â”œâ”€â”€ Line 25: self.build_processors()                                                                â”‚
â”‚  â”‚       â”‚       â”‚   â””â”€â”€ ğŸ”— CALLS: xraygpt/datasets/builders/base_dataset_builder.py::build_processors()             â”‚
â”‚  â”‚       â”‚       â”œâ”€â”€ Line 37: datasets['train'] = dataset_cls(...)                                                   â”‚
â”‚  â”‚       â”‚       â”‚   â””â”€â”€ ğŸ”— CALLS: xraygpt/datasets/datasets/mimic_dataset.py::MIMICDataset.__init__()               â”‚
â”‚  â”‚       â”‚       â””â”€â”€ ğŸ”— RETURNS: {'train': MIMICDataset}                                                             â”‚
â”‚  â”‚       â””â”€â”€ ğŸ”— RETURNS: {'mimic': {'train': MIMICDataset}}                                                          â”‚
â”‚  â”‚                                                                                                                   â”‚
â”‚  â”œâ”€â”€ Line 93:     model = task.build_model(cfg)                                                                      â”‚
â”‚  â”‚   â””â”€â”€ ğŸ”— CALLS: xraygpt/tasks/base_task.py::build_model() [Line 30]                                               â”‚
â”‚  â”‚       â”œâ”€â”€ Line 31: model_config = cfg.model_cfg                                                                   â”‚
â”‚  â”‚       â”œâ”€â”€ Line 33: model_cls = registry.get_model_class(model_config.arch)                                        â”‚
â”‚  â”‚       â”‚   â””â”€â”€ ğŸ”— CALLS: xraygpt/common/registry.py::get_model_class() [Line 235]                                  â”‚
â”‚  â”‚       â”‚       â””â”€â”€ ğŸ”— RETURNS: MiniGPT4 (from xraygpt/models/mini_gpt4.py)                                         â”‚
â”‚  â”‚       â””â”€â”€ Line 34: return model_cls.from_config(model_config)                                                     â”‚
â”‚  â”‚           â””â”€â”€ ğŸ”— CALLS: xraygpt/models/mini_gpt4.py::MiniGPT4.from_config() [Line 337]                            â”‚
â”‚  â”‚               â”œâ”€â”€ Line 357-373: model = cls(...)                                                                  â”‚
â”‚  â”‚               â”‚   â””â”€â”€ ğŸ”— CALLS: xraygpt/models/mini_gpt4.py::MiniGPT4.__init__() [Line 46]                        â”‚
â”‚  â”‚               â”‚       â”œâ”€â”€ Line 66: self.tokenizer = self.init_tokenizer()                                         â”‚
â”‚  â”‚               â”‚       â”œâ”€â”€ Line 70-72: self.visual_encoder, self.ln_vision = self.init_vision_encoder(...)         â”‚
â”‚  â”‚               â”‚       â”œâ”€â”€ Line 86-87: self.Qformer, self.query_tokens = self.init_Qformer(...)                    â”‚
â”‚  â”‚               â”‚       â”œâ”€â”€ Line 107: self.llama_tokenizer = LlamaTokenizer.from_pretrained(...)                    â”‚
â”‚  â”‚               â”‚       â”œâ”€â”€ Line 111-120: self.llama_model = LlamaForCausalLM.from_pretrained(...)                  â”‚
â”‚  â”‚               â”‚       â””â”€â”€ Line 126-128: self.llama_proj = nn.Linear(...)                                          â”‚
â”‚  â”‚               â”œâ”€â”€ Line 375-380: Load checkpoint if exists                                                         â”‚
â”‚  â”‚               â””â”€â”€ ğŸ”— RETURNS: Initialized MiniGPT4 instance                                                       â”‚
â”‚  â”‚                                                                                                                   â”‚
â”‚  â”œâ”€â”€ Line 95-97: runner = get_runner_class(cfg)(cfg=cfg, job_id=job_id, task=task, model=model, datasets=datasets)   â”‚
â”‚  â”‚   â”œâ”€â”€ ğŸ”— CALLS: train.py::get_runner_class() [Line 64]                                                            â”‚
â”‚  â”‚   â”‚   â”œâ”€â”€ Line 68: runner_cls = registry.get_runner_class(cfg.run_cfg.get("runner", "runner_base"))               â”‚
â”‚  â”‚   â”‚   â”‚   â””â”€â”€ ğŸ”— CALLS: xraygpt/common/registry.py::get_runner_class() [Line 251]                                 â”‚
â”‚  â”‚   â”‚   â”‚       â””â”€â”€ ğŸ”— RETURNS: RunnerBase (from xraygpt/runners/runner_base.py)                                    â”‚
â”‚  â”‚   â”‚   â””â”€â”€ ğŸ”— RETURNS: RunnerBase class                                                                            â”‚
â”‚  â”‚   â””â”€â”€ ğŸ”— CALLS: xraygpt/runners/runner_base.py::RunnerBase.__init__() [Line 38]                                   â”‚
â”‚  â”‚                                                                                                                   â”‚
â”‚  â””â”€â”€ Line 98:     runner.train()                                                                                     â”‚
â”‚      â””â”€â”€ ğŸ”— CALLS: xraygpt/runners/runner_base.py::RunnerBase.train() [Line 362]                                     â”‚
â”‚                                                                                                                      â”‚
â”‚                                                                                                                      â”‚
â”‚                                       ğŸ“ PHASE 2: Training Loop Initialization                                       â”‚
â”‚                                                                                                                      â”‚
â”‚                                                                                                                      â”‚
â”‚  ğŸ“ xraygpt/runners/runner_base.py                                                                                   â”‚
â”‚  â”œâ”€â”€ Line 362: def train(self):                                                                                      â”‚
â”‚  â”œâ”€â”€ Line 363:     start_time = time.time()                                                                          â”‚
â”‚  â”œâ”€â”€ Line 364:     best_agg_metric = 0                                                                               â”‚
â”‚  â”œâ”€â”€ Line 365:     best_epoch = 0                                                                                    â”‚
â”‚  â”œâ”€â”€ Line 367:     self.log_config()                                                                                 â”‚
â”‚  â”‚   â””â”€â”€ ğŸ”— CALLS: xraygpt/runners/runner_base.py::log_config() [Line 421]                                           â”‚
â”‚  â”œâ”€â”€ Line 369:     for cur_epoch in range(self.start_epoch, self.max_epoch):                                         â”‚
â”‚  â”œâ”€â”€ Line 370:         if not self.evaluate_only:                                                                    â”‚
â”‚  â”œâ”€â”€ Line 371:             if data_loader is not None:                                                               â”‚
â”‚  â”œâ”€â”€ Line 372:                 self.log_stats(split_name="train", stats=train_stats)                                 â”‚
â”‚  â”œâ”€â”€ Line 377:                 train_stats = self.train_epoch(cur_epoch)                                             â”‚
â”‚  â”‚   â””â”€â”€ ğŸ”— CALLS: xraygpt/runners/runner_base.py::train_epoch() [Line 446]                                          â”‚
â”‚  â”‚       â”œâ”€â”€ Line 447: self.model.train()                                                                            â”‚
â”‚  â”‚       â””â”€â”€ Line 449: return self.task.train_epoch(...)                                                             â”‚
â”‚  â”‚           â””â”€â”€ ğŸ”— CALLS: xraygpt/tasks/base_task.py::train_epoch() [Line 107]                                      â”‚
â”‚  â”‚               â””â”€â”€ Line 119: return self._train_inner_loop(...)                                                    â”‚
â”‚  â”‚                   â””â”€â”€ ğŸ”— CALLS: xraygpt/tasks/base_task.py::_train_inner_loop() [Line 213]                        â”‚
â”‚                                                                                                                      â”‚
â”‚                                                                                                                      â”‚
â”‚                                           ğŸ“ PHASE 3: Inner Training Loop                                            â”‚
â”‚                                                                                                                      â”‚
â”‚                                                                                                                      â”‚
â”‚  ğŸ“ xraygpt/tasks/base_task.py                                                                                       â”‚
â”‚  â”œâ”€â”€ Line 213: def _train_inner_loop(self, epoch, iters_per_epoch, model, data_loader, optimizer, lr_scheduler,      â”‚
â”‚  scaler=None, start_iters=None, log_freq=50, cuda_enabled=False, accum_grad_iters=1):                                â”‚
â”‚  â”œâ”€â”€ Line 233: use_amp = scaler is not None                                                                          â”‚
â”‚  â”œâ”€â”€ Line 235-237: if not hasattr(data_loader, "__next__"): data_loader = iter(data_loader)                          â”‚
â”‚  â”œâ”€â”€ Line 239: metric_logger = MetricLogger(delimiter="  ")                                                          â”‚
â”‚  â”‚   â””â”€â”€ ğŸ”— CALLS: xraygpt/common/logger.py::MetricLogger.__init__()                                                 â”‚
â”‚  â”œâ”€â”€ Line 258: for i in metric_logger.log_every(range(iters_per_epoch), log_freq, header):                           â”‚
â”‚  â”œâ”€â”€ Line 263:     samples = next(data_loader)                                                                       â”‚
â”‚  â”‚   â””â”€â”€ ğŸ”— CALLS: DataLoader.__next__() which triggers:                                                             â”‚
â”‚  â”‚       â””â”€â”€ ğŸ”— CALLS: xraygpt/datasets/datasets/mimic_dataset.py::MIMICDataset.__getitem__() [Line 30]              â”‚
â”‚  â”‚           â”œâ”€â”€ Line 33: ann = self.annotation[index]                                                               â”‚
â”‚  â”‚           â”œâ”€â”€ Line 35: img_file = '{}.jpg'.format(ann["image_id"])                                                â”‚
â”‚  â”‚           â”œâ”€â”€ Line 36: image_path = os.path.join(self.vis_root, img_file)                                         â”‚
â”‚  â”‚           â”œâ”€â”€ Line 37: image = Image.open(image_path).convert("RGB")                                              â”‚
â”‚  â”‚           â”œâ”€â”€ Line 39: image = self.vis_processor(image)                                                          â”‚
â”‚  â”‚           â”‚   â””â”€â”€ ğŸ”— CALLS: xraygpt/processors/blip_processors.py::Blip2ImageTrainProcessor.__call__() [Line 70]  â”‚
â”‚  â”‚           â”‚       â””â”€â”€ Line 71: return self.transform(item)                                                        â”‚
â”‚  â”‚           â”‚           â””â”€â”€ ğŸ”— CALLS: torchvision.transforms.Compose.__call__()                                     â”‚
â”‚  â”‚           â”œâ”€â”€ Line 40: caption = ann['caption']                                                                   â”‚
â”‚  â”‚           â””â”€â”€ ğŸ”— RETURNS: {"image": processed_tensor, "caption": text, "image_id": id}                            â”‚
â”‚  â”‚                                                                                                                   â”‚
â”‚  â”œâ”€â”€ Line 265:     samples = prepare_sample(samples, cuda_enabled=cuda_enabled)                                      â”‚
â”‚  â”‚   â””â”€â”€ ğŸ”— CALLS: xraygpt/datasets/data_utils.py::prepare_sample() [Line 89]                                        â”‚
â”‚  â”‚       â”œâ”€â”€ Line 90-91: if cuda_enabled: samples = move_to_cuda(samples)                                            â”‚
â”‚  â”‚       â”‚   â””â”€â”€ ğŸ”— CALLS: xraygpt/datasets/data_utils.py::move_to_cuda() [Line 82]                                  â”‚
â”‚  â”‚       â”‚       â””â”€â”€ Line 86: return apply_to_sample(_move_to_cuda, sample)                                          â”‚
â”‚  â”‚       â”‚           â””â”€â”€ ğŸ”— CALLS: xraygpt/datasets/data_utils.py::apply_to_sample() [Line 65]                       â”‚
â”‚  â”‚       â””â”€â”€ ğŸ”— RETURNS: GPU-moved samples                                                                           â”‚
â”‚  â”‚                                                                                                                   â”‚
â”‚  â”œâ”€â”€ Line 274:     lr_scheduler.step(cur_epoch=inner_epoch, cur_step=i)                                              â”‚
â”‚  â”‚   â””â”€â”€ ğŸ”— CALLS: xraygpt/common/optims.py::LinearWarmupCosineLRScheduler.step()                                    â”‚
â”‚  â”‚                                                                                                                   â”‚
â”‚  â”œâ”€â”€ Line 276:     with torch.cuda.amp.autocast(enabled=use_amp):                                                    â”‚
â”‚  â”œâ”€â”€ Line 277:         loss = self.train_step(model=model, samples=samples)                                          â”‚
â”‚  â”‚   â””â”€â”€ ğŸ”— CALLS: xraygpt/tasks/base_task.py::train_step() [Line 68]                                                â”‚
â”‚  â”‚       â””â”€â”€ Line 69: loss = model(samples)["loss"]                                                                  â”‚
â”‚  â”‚           â””â”€â”€ ğŸ”— CALLS: xraygpt/models/mini_gpt4.py::MiniGPT4.forward() [Line 190]                                â”‚
â”‚                                                                                                                      â”‚
â”‚                                                                                                                      â”‚
â”‚                                            ğŸ“ PHASE 4: Model Forward Pass                                            â”‚
â”‚                                                                                                                      â”‚
â”‚                                                                                                                      â”‚
â”‚  ğŸ“ xraygpt/models/mini_gpt4.py                                                                                      â”‚
â”‚  â”œâ”€â”€ Line 190: def forward(self, samples):                                                                           â”‚
â”‚  â”œâ”€â”€ Line 191:     image = samples["image"]                                                                          â”‚
â”‚  â”œâ”€â”€ Line 192:     img_embeds, atts_img = self.encode_img(image)                                                     â”‚
â”‚  â”‚   â””â”€â”€ ğŸ”— CALLS: xraygpt/models/mini_gpt4.py::encode_img() [Line 152]                                              â”‚
â”‚  â”‚       â”œâ”€â”€ Line 159: image_embeds = self.ln_vision(self.visual_encoder(image)).to(device)                          â”‚
â”‚  â”‚       â”‚   â”œâ”€â”€ ğŸ”— CALLS: xraygpt/models/eva_vit.py::VisionTransformer.forward()                                    â”‚
â”‚  â”‚       â”‚   â””â”€â”€ ğŸ”— CALLS: torch.nn.LayerNorm.forward()                                                              â”‚
â”‚  â”‚       â”œâ”€â”€ Line 162: query_tokens = self.query_tokens.expand(image_embeds.shape[0], -1, -1)                        â”‚
â”‚  â”‚       â”œâ”€â”€ Line 163-168: query_output = self.Qformer.bert(...)                                                     â”‚
â”‚  â”‚       â”‚   â””â”€â”€ ğŸ”— CALLS: xraygpt/models/Qformer.py::BertModel.forward()                                            â”‚
â”‚  â”‚       â”œâ”€â”€ Line 170: inputs_llama = self.llama_proj(query_output.last_hidden_state)                                â”‚
â”‚  â”‚       â”‚   â””â”€â”€ ğŸ”— CALLS: torch.nn.Linear.forward()                                                                 â”‚
â”‚  â”‚       â””â”€â”€ ğŸ”— RETURNS: (inputs_llama, atts_llama)                                                                  â”‚
â”‚  â”‚                                                                                                                   â”‚
â”‚  â”œâ”€â”€ Line 197-205: if self.prompt_list: prompt = random.choice(self.prompt_list); img_embeds, atts_img =             â”‚
â”‚  self.prompt_wrap(img_embeds, atts_img, prompt)                                                                      â”‚
â”‚  â”‚   â””â”€â”€ ğŸ”— CALLS: xraygpt/models/mini_gpt4.py::prompt_wrap() [Line 174]                                             â”‚
â”‚  â”‚       â”œâ”€â”€ Line 177: p_before, p_after = prompt.split('<ImageHere>')                                               â”‚
â”‚  â”‚       â”œâ”€â”€ Line 178-181: Tokenize prompt parts with self.llama_tokenizer(...)                                      â”‚
â”‚  â”‚       â”œâ”€â”€ Line 182-183: Convert to embeddings with self.llama_model.model.embed_tokens(...)                       â”‚
â”‚  â”‚       â”œâ”€â”€ Line 184: wrapped_img_embeds = torch.cat([p_before_embeds, img_embeds, p_after_embeds], dim=1)          â”‚
â”‚  â”‚       â””â”€â”€ ğŸ”— RETURNS: (wrapped_img_embeds, wrapped_atts_img)                                                      â”‚
â”‚  â”‚                                                                                                                   â”‚
â”‚  â”œâ”€â”€ Line 207: self.llama_tokenizer.padding_side = "right"                                                           â”‚
â”‚  â”œâ”€â”€ Line 209: text = [t + self.end_sym for t in samples["caption"]]                                                 â”‚
â”‚  â”œâ”€â”€ Line 211-218: to_regress_tokens = self.llama_tokenizer(text, ...)                                               â”‚
â”‚  â”‚   â””â”€â”€ ğŸ”— CALLS: transformers.LlamaTokenizer.__call__()                                                            â”‚
â”‚  â”‚                                                                                                                   â”‚
â”‚  â”œâ”€â”€ Line 220-222: targets = to_regress_tokens.input_ids.masked_fill(...)                                            â”‚
â”‚  â”œâ”€â”€ Line 224-227: empty_targets = torch.ones(...).fill_(-100); targets = torch.cat([empty_targets, targets], dim=1  â”‚
â”‚  â”œâ”€â”€ Line 230-233: bos = torch.ones(...) * self.llama_tokenizer.bos_token_id; bos_embeds =                           â”‚
â”‚  self.llama_model.model.embed_tokens(bos)                                                                            â”‚
â”‚  â”œâ”€â”€ Line 237: to_regress_embeds = self.llama_model.model.embed_tokens(to_regress_tokens.input_ids)                  â”‚
â”‚  â”œâ”€â”€ Line 238: inputs_embeds = torch.cat([bos_embeds, img_embeds, to_regress_embeds], dim=1)                         â”‚
â”‚  â”œâ”€â”€ Line 239: attention_mask = torch.cat([atts_bos, atts_img, to_regress_tokens.attention_mask], dim=1)             â”‚
â”‚  â”‚                                                                                                                   â”‚
â”‚  â”œâ”€â”€ Line 241: with self.maybe_autocast():                                                                           â”‚
â”‚  â”œâ”€â”€ Line 242-247: outputs = self.llama_model(inputs_embeds=inputs_embeds, attention_mask=attention_mask,            â”‚
â”‚  return_dict=True, labels=targets)                                                                                   â”‚
â”‚  â”‚   â””â”€â”€ ğŸ”— CALLS: xraygpt/models/modeling_llama.py::LlamaForCausalLM.forward()                                      â”‚
â”‚  â”‚       â””â”€â”€ ğŸ”— CALLS: transformers.models.llama.modeling_llama.LlamaForCausalLM.forward()                           â”‚
â”‚  â”‚                                                                                                                   â”‚
â”‚  â”œâ”€â”€ Line 248: loss = outputs.loss                                                                                   â”‚
â”‚  â””â”€â”€ Line 250: return {"loss": loss}                                                                                 â”‚
â”‚      â””â”€â”€ ğŸ”— RETURNS: {"loss": computed_loss_tensor}                                                                  â”‚
â”‚                                                                                                                      â”‚
â”‚                                                                                                                      â”‚
â”‚                                       ğŸ“ PHASE 5: Backward Pass & Optimization                                       â”‚
â”‚                                                                                                                      â”‚
â”‚                                                                                                                      â”‚
â”‚  ğŸ“ xraygpt/tasks/base_task.py                                                                                       â”‚
â”‚  â”œâ”€â”€ Line 280: if use_amp:                                                                                           â”‚
â”‚  â”œâ”€â”€ Line 281:     scaler.scale(loss).backward()                                                                     â”‚
â”‚  â”‚   â””â”€â”€ ğŸ”— CALLS: torch.cuda.amp.GradScaler.scale() â†’ torch.Tensor.backward()                                       â”‚
â”‚  â”œâ”€â”€ Line 282: else:                                                                                                 â”‚
â”‚  â”œâ”€â”€ Line 283:     loss.backward()                                                                                   â”‚
â”‚  â”‚   â””â”€â”€ ğŸ”— CALLS: torch.Tensor.backward()                                                                           â”‚
â”‚  â”‚                                                                                                                   â”‚
â”‚  â”œâ”€â”€ Line 286: if (i + 1) % accum_grad_iters == 0:                                                                   â”‚
â”‚  â”œâ”€â”€ Line 287:     if use_amp:                                                                                       â”‚
â”‚  â”œâ”€â”€ Line 288:         scaler.step(optimizer)                                                                        â”‚
â”‚  â”‚   â””â”€â”€ ğŸ”— CALLS: torch.cuda.amp.GradScaler.step()                                                                  â”‚
â”‚  â”œâ”€â”€ Line 289:         scaler.update()                                                                               â”‚
â”‚  â”‚   â””â”€â”€ ğŸ”— CALLS: torch.cuda.amp.GradScaler.update()                                                                â”‚
â”‚  â”œâ”€â”€ Line 290:     else:                                                                                             â”‚
â”‚  â”œâ”€â”€ Line 291:         optimizer.step()                                                                              â”‚
â”‚  â”‚   â””â”€â”€ ğŸ”— CALLS: torch.optim.AdamW.step()                                                                          â”‚
â”‚  â”œâ”€â”€ Line 292:     optimizer.zero_grad()                                                                             â”‚
â”‚  â”‚   â””â”€â”€ ğŸ”— CALLS: torch.optim.AdamW.zero_grad()                                                                     â”‚
â”‚  â”‚                                                                                                                   â”‚
â”‚  â”œâ”€â”€ Line 294: metric_logger.update(loss=loss.item())                                                                â”‚
â”‚  â”œâ”€â”€ Line 295: metric_logger.update(lr=optimizer.param_groups[0]["lr"])                                              â”‚
â”‚  â””â”€â”€ Loop continues until iters_per_epoch completed                                                                  â”‚
â”‚                                                                                                                      â”‚
â”‚                                                                                                                      â”‚
â”‚                                         ğŸ“ PHASE 6: Epoch Completion & Loop                                          â”‚
â”‚                                                                                                                      â”‚
â”‚                                                                                                                      â”‚
â”‚  ğŸ“ xraygpt/tasks/base_task.py                                                                                       â”‚
â”‚  â”œâ”€â”€ Line 298-300: metric_logger.synchronize_between_processes(); logging.info("Averaged stats: " +                  â”‚
â”‚  str(metric_logger.global_avg()))                                                                                    â”‚
â”‚  â””â”€â”€ Line 301-304: return {k: "{:.3f}".format(meter.global_avg) for k, meter in metric_logger.meters.items()}        â”‚
â”‚      â””â”€â”€ ğŸ”— RETURNS: Training statistics dictionary                                                                  â”‚
â”‚                                                                                                                      â”‚
â”‚  ğŸ“ xraygpt/runners/runner_base.py                                                                                   â”‚
â”‚  â”œâ”€â”€ Line 377: train_stats = self.train_epoch(cur_epoch) [COMPLETED]                                                 â”‚
â”‚  â”œâ”€â”€ Line 378: self.log_stats(split_name="train", stats=train_stats)                                                 â”‚
â”‚  â”œâ”€â”€ Line 380-390: Validation and checkpointing logic                                                                â”‚
â”‚  â””â”€â”€ Line 369: for cur_epoch in range(...): [CONTINUES TO NEXT EPOCH]                                                â”‚
â”‚                                                                                                                      â”‚
â”‚                                                                                                                      â”‚
â”‚ This complete trace shows every single line connection from the initial train.py execution through the entire        â”‚
â”‚ training loop, including all function calls, file transitions, and data flow paths. 
