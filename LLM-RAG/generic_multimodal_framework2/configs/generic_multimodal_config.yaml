# Generic Multimodal Framework Configuration
# This configuration is completely customizable - no hardcoded defaults
# All parameters must be specified for your specific use case

# Domain Configuration
domain:
  name: "medical"  # Options: medical, generic, satellite, legal, financial, custom
  description: "Medical imaging and text analysis"

# Data Validation Configuration
validation:
  domain: "medical"
  domain_name: "medical"  # Used in error messages
  min_image_size: [224, 224]
  max_image_size: [1024, 1024]
  min_text_length: 5
  max_text_length: 1000
  forbidden_text_patterns: ["xxxx", "redacted", "###", "[REDACTED]", "[PHI]"]
  required_channels: [1, 3]  # Grayscale or RGB
  require_domain_content: false  # Set to true to enforce domain-specific content
  convert_to_grayscale: false
  apply_histogram_equalization: true
  
  # Domain-specific keywords for content validation
  domain_keywords: ["chest", "lung", "heart", "radiograph", "x-ray", "ct", "mri", "patient", "diagnosis", "findings", "impression", "abnormal", "normal"]
  
  # Domain-specific text replacements/standardization
  domain_replacements:
    "xray": "x-ray"
    "cxr": "chest x-ray"
    "pa and lateral": "posteroanterior and lateral"
    "lat": "lateral"
    "ap": "anteroposterior"

# Tokenization Configuration - All parameters required
tokenization:
  text:
    type: "text"  # Options: text, vision, multimodal
    tokenizer_type: "bert"  # Options: bert, llama, gpt2, t5, auto
    model_name: "bert-base-uncased"
    max_length: 512
    padding: "max_length"
    truncation: true
    add_special_tokens: true
    special_tokens: {}  # Add custom special tokens if needed
  
  image:
    type: "vision"  # Options: text, vision, multimodal
    method: "patch"  # Options: patch, vqvae
    patch_size: 16
    image_size: 224
    vocab_size: 8192  # For discrete tokenization methods
  
  multimodal:
    type: "multimodal"
    text_tokenizer:
      tokenizer_type: "bert"
      model_name: "bert-base-uncased"
    vision_tokenizer:
      method: "patch"
      patch_size: 16
      image_size: 224
    image_token: "<IMAGE>"
    image_start_token: "<IMG>"
    image_end_token: "</IMG>"

# Encoding Configuration - All parameters required
encoding:
  device: "cuda"  # Required: cuda, cpu, auto
  
  text:
    type: "bert"  # Options: bert, roberta, clip_text, medical_bert
    model_name: "bert-base-uncased"
    hidden_size: 768
    device: "cuda"
    pooling_strategy: "cls"  # Options: cls, mean, max
    freeze_encoder: false
    encoder_type: "bert"  # Specific encoder implementation
    
  image:
    type: "vision_transformer"  # Options: vision_transformer, clip_vision, resnet, medical_clip
    model_name: "google/vit-base-patch16-224"
    hidden_size: 768
    device: "cuda"
    freeze_encoder: false
    encoder_type: "vision_transformer"
    image_size: 224
    patch_size: 16
    
  fusion:
    hidden_size: 768
    device: "cuda"
    alignment_method: "linear"  # Options: linear, mlp, attention
    normalize_embeddings: true

# Attention Configuration
attention:
  self_attention:
    enabled: true
    num_attention_heads: 12
    hidden_size: 768
    attention_dropout: 0.1
    layer_norm_eps: 1e-12
    
  cross_attention:
    enabled: true
    num_attention_heads: 12
    hidden_size: 768
    attention_dropout: 0.1
    cross_attention_freq: 2
    save_attention: true
    
  qformer:
    enabled: false
    num_query_tokens: 32
    num_layers: 6
    cross_attention_freq: 2

# Decoding Configuration
decoding:
  type: "llm"  # Options: llm, transformer
  model_name: "microsoft/DialoGPT-medium"  # Can be changed to any compatible model
  max_new_tokens: 256
  temperature: 0.7
  top_p: 0.9
  top_k: 50
  do_sample: true
  num_beams: 1
  repetition_penalty: 1.1
  length_penalty: 1.0
  early_stopping: true
  pad_token_id: 50256
  eos_token_id: 50256

# Model Configuration - All parameters required
model:
  name: "GenericMultiModalModel"
  device: "cuda"  # Required: cuda, cpu
  dtype: "float16"  # Options: float16, float32, bfloat16
  gradient_checkpointing: false
  training_mode: false  # Set to true for training
  
# Training Configuration (optional)
training:
  learning_rate: 1e-4
  weight_decay: 0.01
  warmup_steps: 1000
  max_steps: 10000
  gradient_accumulation_steps: 1
  max_grad_norm: 1.0
  
# Evaluation Configuration (optional)
evaluation:
  batch_size: 8
  metrics: ["bleu", "rouge", "bertscore"]
  save_predictions: true
  
# Logging Configuration
logging:
  level: "INFO"
  save_attention_maps: true
  log_validation_results: true
  tensorboard_logging: false