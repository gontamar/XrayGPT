# BERT Tokenizer Configuration
tokenizers:
  bert:
    model_name: "bert-base-uncased"
    special_tokens:
      bos_token: "[DEC]"
    max_length: 512
    padding: true
    truncation: true
    return_tensors: "pt"

# Image Processor Configuration
image_processors:
  blip2:
    type: "blip2"
    image_size: 224
    normalize_mean: [0.48145466, 0.4578275, 0.40821073]
    normalize_std: [0.26862954, 0.26130258, 0.27577711]
    enable_patch_embed: true
    patch_size: 16
    in_channels: 3
    embed_dim: 768
    enable_vision_transformer: true
    vit_type: "vit_base"
    drop_path_rate: 0.4
    use_checkpoint: false
    precision: "fp16"
  
  clip:
    type: "clip"
    image_size: 224
    normalize_mean: [0.485, 0.456, 0.406]
    normalize_std: [0.229, 0.224, 0.225]
    enable_patch_embed: false
    patch_size: 16
    in_channels: 3
    embed_dim: 512

# Vision Transformer Configuration
vision_transformers:
  vit_base:
    type: "vit_base"
    img_size: 224
    patch_size: 16
    embed_dim: 768
    depth: 12
    num_heads: 12
    mlp_ratio: 4
    drop_path_rate: 0.1
    precision: "fp32"
    
  vit_large:
    type: "vit_large"
    img_size: 224
    patch_size: 16
    embed_dim: 1024
    depth: 24
    num_heads: 16
    mlp_ratio: 4
    drop_path_rate: 0.2
    precision: "fp32"
    
  eva_vit_g:
    type: "eva_vit_g"
    img_size: 224
    patch_size: 14
    embed_dim: 1408
    depth: 39
    num_heads: 16
    mlp_ratio: 4.3637
    drop_path_rate: 0.4
    precision: "fp16"
    use_checkpoint: false

