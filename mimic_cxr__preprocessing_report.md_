# MIMIC-CXR Preprocessing Report

## Overview

The preprocessing of the MIMIC-CXR dataset is a critical step for ensuring high-quality, interactive, and concise medical summaries for training vision-language models like XrayGPT. The pipeline involves filtering, cleaning, and augmenting report texts, followed by generating summaries with GPT-3.5-turbo, and finally pairing each summary with its corresponding image. The final output is typically a JSON file (`filter_cap.json`) containing image-summary pairs.

---

## Steps

### 1. **Filtering Reports**
- **Remove incomplete reports:** Only keep reports containing both the "findings" and "impression" sections.
- **Remove short findings:** Exclude reports with a findings section of less than 10 words.
- **Remove short impressions:** Exclude reports with an impression section of less than 2 words.

### 2. **Cleaning and Refining**
- **Remove sentences with prior comparisons:** Any sentence comparing to prior studies (e.g., "compared to prior", "previous study", etc.) is deleted.
- **Remove de-identification symbols:** Tokens like `"__"` are removed.
- **Remove view information:** Sentences describing imaging views (e.g., "PA and lateral views") are excluded.

### 3. **Summarization**
- **Use GPT-3.5-turbo:** The cleaned findings and impression are combined and sent to GPT-3.5-turbo to generate a single, high-quality, interactive summary.

### 4. **Pairing**
- **Link Summary to Image:** The summary is paired with the corresponding CXR image using unique identifiers.

### 5. **Final Output**
- The result is a JSON file (e.g., `filter_cap.json`) with each entry containing:
    - `image_path`: Path to the image file.
    - `summary`: The cleaned, high-quality summary.

---

## Example: Before and After

**Input Findings:**  
PA and lateral views of the chest were provided demonstrating no focal consolidation, effusion or pneumothorax. Cardiomediastinal silhouette appears normal and stable. There is a compression deformity involving a mid thoracic vertebral body, which appears new from the prior chest radiograph of ___. No free air below the right hemidiaphragm. There are tiny surgical clips in the left base of neck, likely indicating prior thyroid surgery.

**Input Impression:**  
No acute intrathoracic process. Interval development of a mid thoracic spine compression fracture.

**After Preprocessing and Summarization:**  
The chest x-ray findings reveal no evidence of focal consolidation, effusion, or pneumothorax. The cardiomediastinal silhouette appears stable and normal. There is a newly developed mid thoracic spine compression fracture but no free air below the right hemidiaphragm. The presence of surgical clips in the left base of the neck suggests prior thyroid surgery. The impression suggests that there is no acute intrathoracic condition detected in the x-ray aside from the new development of mid thoracic spine compression fracture.

---

## Implementation in XrayGPT

- **Preprocessing scripts** are referenced in `README-DATASET.md`. These are typically run before model training and generate the `filter_cap.json` file.
- **Dataset loading** is handled by `xraygpt/datasets/datasets/mimic_dataset.py` which reads the preprocessed JSON.
- The actual filtering/cleaning code is often custom Python, not always in the repo, but the following example demonstrates the logic.

---

## Example Preprocessing Python Script

```python name=preprocess_mimic_cxr.py
import json
import re
from openai import OpenAI

def has_section(text, section_name):
    return section_name.lower() in text.lower()

def clean_text(text):
    # Remove sentences with prior comparisons
    text = re.sub(r'[^.]*prior[^.]*\.', '', text, flags=re.IGNORECASE)
    text = re.sub(r'[^.]*previous[^.]*\.', '', text, flags=re.IGNORECASE)
    # Remove de-identified symbols
    text = text.replace('__', '')
    # Remove view information
    text = re.sub(r'[^.]*view[^.]*\.', '', text, flags=re.IGNORECASE)
    return text.strip()

def summarize_with_gpt(findings, impression, client):
    prompt = f"Findings: {findings}\nImpression: {impression}\n\nSummarize these into a concise, interactive radiology report for a chest x-ray."
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}],
        max_tokens=256
    )
    return response.choices[0].message.content.strip()

def preprocess_reports(input_path, output_path, openai_api_key):
    # Load the raw annotation file (e.g., mimic_raw_reports.json)
    with open(input_path, "r") as f:
        raw_data = json.load(f)

    processed = []
    client = OpenAI(api_key=openai_api_key)
    for entry in raw_data:
        findings = entry.get("findings", "")
        impression = entry.get("impression", "")
        image_path = entry.get("image_path", "")

        # Filter incomplete/short reports
        if not findings or not impression:
            continue
        if len(findings.split()) < 10 or len(impression.split()) < 2:
            continue

        # Clean text
        cleaned_findings = clean_text(findings)
        cleaned_impression = clean_text(impression)

        # Summarize with GPT (rate-limited in practice!)
        summary = summarize_with_gpt(cleaned_findings, cleaned_impression, client)

        processed.append({"image_path": image_path, "summary": summary})

    # Save output
    with open(output_path, "w") as f:
        json.dump(processed, f, indent=2)

# Example usage:
# preprocess_reports("mimic_raw_reports.json", "filter_cap.json", openai_api_key="sk-...")
```

---

## Notes

- In actual use, the OpenAI API should be called in batches and rate-limited. Consider using an offline LLM if needed.
- The repo expects the output JSON to follow the structure shown above.
- For OpenI and other datasets, adapt the same script with small modifications.

---

## References

- XrayGPT [`README-DATASET.md`](https://github.com/gontamar/XrayGPT/blob/main/README-DATASET.md)
- XrayGPT [`xraygpt/datasets/datasets/mimic_dataset.py`](https://github.com/gontamar/XrayGPT/blob/main/xraygpt/datasets/datasets/mimic_dataset.py)
- XrayGPT Paper: [XRAYGPT.pdf](https://github.com/gontamar/XrayGPT/blob/main/XRAYGPT.pdf)
